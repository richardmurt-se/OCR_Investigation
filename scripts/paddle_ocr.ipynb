{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PaddleOCR Invoice Processing\n",
        "\n",
        "This notebook processes invoice images using PaddleOCR with GPU acceleration on Kaggle.\n",
        "Uses the classic stable API (`ocr.ocr()`) for reliable text extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Install dependencies\n",
        "# Use PaddlePaddle GPU with CUDA 11.8 (matches Kaggle T4 GPU environment)\n",
        "!pip install paddlepaddle-gpu==3.2.2 -i https://www.paddlepaddle.org.cn/packages/stable/cu118/ --quiet\n",
        "!pip install \"paddleocr>=2.6,<3\" PyMuPDF --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Verify GPU and initialize\n",
        "import paddle\n",
        "print(f\"PaddlePaddle version: {paddle.__version__}\")\n",
        "print(f\"GPU available: {paddle.device.is_compiled_with_cuda()}\")\n",
        "print(f\"GPU count: {paddle.device.cuda.device_count()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Setup and initialize PaddleOCR\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "from paddleocr import PaddleOCR\n",
        "\n",
        "# Configuration\n",
        "INPUT_DIR = Path(\"/kaggle/input/synthetic-invoices\")\n",
        "OUTPUT_DIR = Path(\"/kaggle/working/paddleocr\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "(OUTPUT_DIR / \"raw\").mkdir(exist_ok=True)\n",
        "\n",
        "# Initialize PaddleOCR using the classic stable API\n",
        "# - use_angle_cls=True: detect rotated text\n",
        "# - lang='en': use English-optimized models\n",
        "# - use_gpu=True: leverage Kaggle T4 GPU\n",
        "# - show_log=False: reduce noise in output\n",
        "print(\"Initializing PaddleOCR...\")\n",
        "ocr = PaddleOCR(\n",
        "    use_angle_cls=True,\n",
        "    lang='en',\n",
        "    use_gpu=True,\n",
        "    show_log=False\n",
        ")\n",
        "print(\"PaddleOCR initialized!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Define processing function\n",
        "def process_image(image_path, ocr):\n",
        "    \"\"\"Process a single image with PaddleOCR using the classic stable API.\"\"\"\n",
        "    start_time = time.time()\n",
        "    \n",
        "    try:\n",
        "        # Run OCR using the classic ocr.ocr() method (stable, well-tested)\n",
        "        result = ocr.ocr(str(image_path), cls=True)\n",
        "        \n",
        "        # Extract text from results\n",
        "        # Classic API returns: [page1_results, page2_results, ...]\n",
        "        # Each page result is a list of: [bbox, (text, confidence)]\n",
        "        lines = []\n",
        "        raw_data = []\n",
        "        \n",
        "        if result:\n",
        "            for page in result:\n",
        "                if page:\n",
        "                    for line in page:\n",
        "                        bbox, (text, confidence) = line\n",
        "                        if text:  # Skip empty strings\n",
        "                            lines.append(text)\n",
        "                            raw_data.append({\n",
        "                                \"text\": text,\n",
        "                                \"confidence\": float(confidence),\n",
        "                                \"bbox\": bbox\n",
        "                            })\n",
        "        \n",
        "        full_text = \"\\n\".join(lines)\n",
        "        processing_time = time.time() - start_time\n",
        "        \n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"raw_text\": full_text,\n",
        "            \"raw_data\": raw_data,\n",
        "            \"processing_time_seconds\": round(processing_time, 3)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"error\": f\"{str(e)}\\n{traceback.format_exc()}\",\n",
        "            \"processing_time_seconds\": time.time() - start_time\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Test on a single image before batch processing\n",
        "# This validates that the OCR pipeline is working correctly\n",
        "image_files = sorted(list(INPUT_DIR.glob(\"*.png\")) + list(INPUT_DIR.glob(\"*.jpeg\")) + list(INPUT_DIR.glob(\"*.pdf\")))\n",
        "print(f\"Found {len(image_files)} images total\")\n",
        "\n",
        "if image_files:\n",
        "    test_img = image_files[0]\n",
        "    print(f\"\\nTesting on: {test_img.name}\")\n",
        "    \n",
        "    # Run OCR and print raw result for debugging\n",
        "    test_result = ocr.ocr(str(test_img), cls=True)\n",
        "    print(f\"Result type: {type(test_result)}\")\n",
        "    print(f\"Number of pages: {len(test_result) if test_result else 0}\")\n",
        "    \n",
        "    if test_result and test_result[0]:\n",
        "        print(f\"Detections on page 1: {len(test_result[0])}\")\n",
        "        # Show first 3 detections as a sample\n",
        "        for i, line in enumerate(test_result[0][:3]):\n",
        "            bbox, (text, confidence) = line\n",
        "            print(f\"  [{i}] text='{text}', confidence={confidence:.4f}\")\n",
        "        print(\"  ...\")\n",
        "        print(\"\\nOCR pipeline is working correctly!\")\n",
        "    else:\n",
        "        print(\"\\nWARNING: No text detected! Check GPU/model initialization.\")\n",
        "        print(f\"Raw result: {test_result}\")\n",
        "else:\n",
        "    print(\"ERROR: No images found in input directory!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Process all images\n",
        "# image_files was already populated in the test cell above\n",
        "print(f\"Processing {len(image_files)} images...\")\n",
        "\n",
        "# Process all images\n",
        "empty_count = 0\n",
        "results = []\n",
        "for i, image_path in enumerate(image_files):\n",
        "    print(f\"Processing {i+1}/{len(image_files)}: {image_path.name}\", end=\"\")\n",
        "    \n",
        "    result = process_image(image_path, ocr)\n",
        "    \n",
        "    if not result.get(\"raw_text\"):\n",
        "        empty_count += 1\n",
        "        print(f\" - WARNING: no text extracted!\", end=\"\")\n",
        "    \n",
        "    print()\n",
        "    \n",
        "    # Create output structure\n",
        "    output = {\n",
        "        \"filename\": image_path.name,\n",
        "        \"model_name\": \"paddleocr\",\n",
        "        \"raw_text\": result.get(\"raw_text\", \"\"),\n",
        "        \"processing_time_seconds\": result.get(\"processing_time_seconds\", 0),\n",
        "        \"file_size_bytes\": image_path.stat().st_size,\n",
        "        \"success\": result.get(\"success\", False)\n",
        "    }\n",
        "    \n",
        "    if not result[\"success\"]:\n",
        "        output[\"error\"] = result.get(\"error\", \"Unknown error\")\n",
        "    \n",
        "    results.append(output)\n",
        "    \n",
        "    # Save individual result\n",
        "    result_file = OUTPUT_DIR / f\"{image_path.stem}_{image_path.suffix.lstrip('.')}.json\"\n",
        "    with open(result_file, \"w\") as f:\n",
        "        json.dump(output, f, indent=2)\n",
        "    \n",
        "    # Save raw response\n",
        "    raw_file = OUTPUT_DIR / \"raw\" / f\"{image_path.stem}_{image_path.suffix.lstrip('.')}_raw.json\"\n",
        "    with open(raw_file, \"w\") as f:\n",
        "        json.dump({\n",
        "            \"content\": result.get(\"raw_text\", \"\"),\n",
        "            \"detections\": result.get(\"raw_data\", [])\n",
        "        }, f, indent=2)\n",
        "\n",
        "print(f\"\\nCompleted! Processed {len(results)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Save combined results and summary\n",
        "# Save all results to single file\n",
        "all_results_file = OUTPUT_DIR / \"all_results.json\"\n",
        "with open(all_results_file, \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "# Print summary\n",
        "successful = sum(1 for r in results if r.get(\"success\", False))\n",
        "with_text = sum(1 for r in results if r.get(\"raw_text\", \"\"))\n",
        "total_time = sum(r.get(\"processing_time_seconds\", 0) for r in results)\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Total images: {len(results)}\")\n",
        "print(f\"  Successful: {successful}\")\n",
        "print(f\"  With text extracted: {with_text}\")\n",
        "print(f\"  Empty results: {empty_count}\")\n",
        "print(f\"  Failed: {len(results) - successful}\")\n",
        "print(f\"  Total processing time: {total_time:.1f}s\")\n",
        "print(f\"  Average time per image: {total_time/len(results):.2f}s\")\n",
        "print(f\"\\nResults saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Create downloadable ZIP\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(\n",
        "    \"/kaggle/working/paddle_ocr\",\n",
        "    'zip',\n",
        "    OUTPUT_DIR\n",
        ")\n",
        "print(\"ZIP created: /kaggle/working/paddle_ocr.zip\")\n",
        "print(\"Download from the Output tab after notebook completes.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
