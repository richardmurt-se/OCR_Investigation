{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DeepSeek-OCR-2 Invoice Processing\n",
        "\n",
        "This notebook processes invoice images using DeepSeek-OCR-2 (3B) with GPU acceleration on Kaggle.\n",
        "Uses the custom `model.infer()` API with the `deepseek-ai/DeepSeek-OCR-2` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Install dependencies\n",
        "# DeepSeek-OCR-2 requires pinned transformers==4.46.3 and flash-attn\n",
        "# PyMuPDF provides native PDF support (model handles PDFs directly)\n",
        "!pip install transformers==4.46.3 tokenizers==0.20.3 --quiet\n",
        "!pip install einops addict easydict Pillow numpy PyMuPDF img2pdf --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Verify GPU\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Setup and initialize DeepSeek-OCR-2\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from pathlib import Path\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# Configuration\n",
        "INPUT_DIR = Path(\"/kaggle/input/synthetic-invoices-test\")\n",
        "OUTPUT_DIR = Path(\"/kaggle/working/deepseek-ocr-2\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "(OUTPUT_DIR / \"raw\").mkdir(exist_ok=True)\n",
        "\n",
        "MODEL_NAME = \"deepseek-ai/DeepSeek-OCR-2\"\n",
        "\n",
        "# Initialize DeepSeek-OCR-2\n",
        "# - trust_remote_code=True: required for custom model architecture\n",
        "# - flash_attention_2: required for inference\n",
        "# - BF16 precision: optimal for this model\n",
        "print(\"Loading DeepSeek-OCR-2 model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "model = AutoModel.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    _attn_implementation='eager',\n",
        "    trust_remote_code=True,\n",
        "    use_safetensors=True\n",
        ")\n",
        "model = model.eval().cuda().to(torch.bfloat16)\n",
        "print(\"DeepSeek-OCR-2 loaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Define processing function\n",
        "import io\n",
        "import contextlib\n",
        "\n",
        "def process_image(image_path, model, tokenizer):\n",
        "    \"\"\"Process a single image or PDF with DeepSeek-OCR-2, capturing stdout.\"\"\"\n",
        "    start_time = time.time()\n",
        "\n",
        "    prompt = \"<<image>>\\n<<|grounding|>>Convert the document to markdown.\"\n",
        "\n",
        "    try:\n",
        "        # Capture stdout since model.infer() prints output instead of returning it\n",
        "        stdout_capture = io.StringIO()\n",
        "        with contextlib.redirect_stdout(stdout_capture):\n",
        "            result = model.infer(\n",
        "                tokenizer,\n",
        "                prompt=prompt,\n",
        "                image_file=str(image_path),\n",
        "                output_path=\"/tmp/deepseek_ocr_tmp\",\n",
        "                base_size=1024,\n",
        "                image_size=768,\n",
        "                crop_mode=True,\n",
        "                save_results=False\n",
        "            )\n",
        "\n",
        "        # Get captured output - this contains the actual OCR text\n",
        "        captured_output = stdout_capture.getvalue()\n",
        "\n",
        "        # Clean up captured output - remove debug lines (BASE:, PATCHES:, === lines)\n",
        "        lines = captured_output.strip().split('\\n')\n",
        "        cleaned_lines = [l for l in lines if not l.startswith(('=', 'BASE:', 'PATCHES:'))]\n",
        "        output_text = '\\n'.join(cleaned_lines).strip()\n",
        "\n",
        "        # Use return value if valid string, otherwise use cleaned captured stdout\n",
        "        if result and isinstance(result, str) and result.strip() and result.strip() != \"None\":\n",
        "            output_text = result.strip()\n",
        "\n",
        "        processing_time = time.time() - start_time\n",
        "\n",
        "        return {\n",
        "            \"success\": True,\n",
        "            \"raw_text\": output_text,\n",
        "            \"raw_data\": [{\"text\": output_text}] if output_text else [],\n",
        "            \"processing_time_seconds\": round(processing_time, 3)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        return {\n",
        "            \"success\": False,\n",
        "            \"error\": f\"{str(e)}\\n{traceback.format_exc()}\",\n",
        "            \"raw_text\": \"\",\n",
        "            \"raw_data\": [],\n",
        "            \"processing_time_seconds\": time.time() - start_time\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Test on a single image before batch processing\n",
        "image_files = sorted(\n",
        "    list(INPUT_DIR.glob(\"*.png\")) +\n",
        "    list(INPUT_DIR.glob(\"*.jpeg\")) +\n",
        "    list(INPUT_DIR.glob(\"*.pdf\"))\n",
        ")\n",
        "print(f\"Found {len(image_files)} files total\")\n",
        "\n",
        "if image_files:\n",
        "    test_img = image_files[0]\n",
        "    print(f\"\\nTesting on: {test_img.name}\")\n",
        "\n",
        "    test_result = process_image(test_img, model, tokenizer)\n",
        "    print(f\"Success: {test_result['success']}\")\n",
        "    print(f\"Processing time: {test_result['processing_time_seconds']:.2f}s\")\n",
        "\n",
        "    if test_result[\"raw_text\"]:\n",
        "        preview = test_result[\"raw_text\"][:500]\n",
        "        print(f\"Text preview ({len(test_result['raw_text'])} chars):\\n{preview}\")\n",
        "        print(\"\\nOCR pipeline is working correctly!\")\n",
        "    else:\n",
        "        print(\"\\nWARNING: No text extracted!\")\n",
        "        if test_result.get(\"error\"):\n",
        "            print(f\"Error: {test_result['error']}\")\n",
        "else:\n",
        "    print(\"ERROR: No images found in input directory!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Process all images\n",
        "print(f\"Processing {len(image_files)} files...\")\n",
        "\n",
        "empty_count = 0\n",
        "results = []\n",
        "for i, image_path in enumerate(image_files):\n",
        "    print(f\"Processing {i+1}/{len(image_files)}: {image_path.name}\", end=\"\")\n",
        "\n",
        "    result = process_image(image_path, model, tokenizer)\n",
        "\n",
        "    if not result.get(\"raw_text\"):\n",
        "        empty_count += 1\n",
        "        print(\" - WARNING: no text extracted!\", end=\"\")\n",
        "\n",
        "    print()\n",
        "\n",
        "    # Create output structure\n",
        "    output = {\n",
        "        \"filename\": image_path.name,\n",
        "        \"model_name\": \"deepseek-ocr-2\",\n",
        "        \"raw_text\": result.get(\"raw_text\", \"\"),\n",
        "        \"processing_time_seconds\": result.get(\"processing_time_seconds\", 0),\n",
        "        \"file_size_bytes\": image_path.stat().st_size,\n",
        "        \"success\": result.get(\"success\", False)\n",
        "    }\n",
        "\n",
        "    if not result[\"success\"]:\n",
        "        output[\"error\"] = result.get(\"error\", \"Unknown error\")\n",
        "\n",
        "    results.append(output)\n",
        "\n",
        "    # Save individual result\n",
        "    result_file = OUTPUT_DIR / f\"{image_path.stem}_{image_path.suffix.lstrip('.')}.json\"\n",
        "    with open(result_file, \"w\") as f:\n",
        "        json.dump(output, f, indent=2)\n",
        "\n",
        "    # Save raw response\n",
        "    raw_file = OUTPUT_DIR / \"raw\" / f\"{image_path.stem}_{image_path.suffix.lstrip('.')}_raw.json\"\n",
        "    with open(raw_file, \"w\") as f:\n",
        "        json.dump({\n",
        "            \"content\": result.get(\"raw_text\", \"\"),\n",
        "            \"detections\": result.get(\"raw_data\", [])\n",
        "        }, f, indent=2)\n",
        "\n",
        "print(f\"\\nCompleted! Processed {len(results)} files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Save combined results and summary\n",
        "all_results_file = OUTPUT_DIR / \"all_results.json\"\n",
        "with open(all_results_file, \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "# Print summary\n",
        "successful = sum(1 for r in results if r.get(\"success\", False))\n",
        "with_text = sum(1 for r in results if r.get(\"raw_text\", \"\"))\n",
        "total_time = sum(r.get(\"processing_time_seconds\", 0) for r in results)\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Total files: {len(results)}\")\n",
        "print(f\"  Successful: {successful}\")\n",
        "print(f\"  With text extracted: {with_text}\")\n",
        "print(f\"  Empty results: {empty_count}\")\n",
        "print(f\"  Failed: {len(results) - successful}\")\n",
        "print(f\"  Total processing time: {total_time:.1f}s\")\n",
        "print(f\"  Average time per file: {total_time/len(results):.2f}s\")\n",
        "print(f\"\\nResults saved to: {OUTPUT_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Create downloadable ZIP\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(\n",
        "    \"/kaggle/working/deepseek_ocr2\",\n",
        "    'zip',\n",
        "    OUTPUT_DIR\n",
        ")\n",
        "print(\"ZIP created: /kaggle/working/deepseek_ocr2.zip\")\n",
        "print(\"Download from the Output tab after notebook completes.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
